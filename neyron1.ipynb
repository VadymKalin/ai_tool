{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO16EggNyS7FVk2PSahsSCJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VadymKalin/ai_tool/blob/main/neyron1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X08BVHwvhx7D",
        "outputId": "5efc51c5-16d9-4d79-fe9d-f2843517ffcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1200, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1087, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0758, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0535, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0486, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0478, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0464, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
            "tensor([[-0.0262],\n",
            "        [ 0.0147],\n",
            "        [ 0.8309],\n",
            "        ...,\n",
            "        [-0.0158],\n",
            "        [ 0.0796],\n",
            "        [ 0.0310]])\n",
            "tensor(-0.7336)\n",
            "tensor(1.5023)\n",
            "Time elapsed: 50.80347466468811\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "t_start = time.time()\n",
        "\n",
        "df = pd.read_csv(\"./data/SMSSpamCollection\", sep=\"\\t\", names=[\"type\", \"message\"])\n",
        "\n",
        "df[\"spam\"] = df[\"type\"] == \"spam\"\n",
        "df.drop(\"type\", axis=1, inplace=True)\n",
        "\n",
        "cv = CountVectorizer(max_features=1000)\n",
        "messages = cv.fit_transform(df['message'])\n",
        "\n",
        "X = torch.tensor(messages.todense(), dtype=torch.float32)\n",
        "y = torch.tensor(df[\"spam\"], dtype=torch.float32).reshape((-1, 1))\n",
        "\n",
        "model = nn.Linear(1000, 1)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "for i in range(0, 10000):\n",
        "  # Training pass\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(X)\n",
        "  loss = loss_fn(outputs, y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if i % 100 == 0:\n",
        "    print(loss)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  y_pred = model(X)\n",
        "  print(y_pred)\n",
        "  print(y_pred.min())\n",
        "  print(y_pred.max())\n",
        "\n",
        "\n",
        "t_end = time.time()\n",
        "print(f\"Time elapsed: {t_end - t_start}\")"
      ]
    }
  ]
}